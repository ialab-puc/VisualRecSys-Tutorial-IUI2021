{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T15:20:53.542195Z",
     "start_time": "2020-04-06T15:20:53.367196Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.multiprocessing\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import RandomSampler, SequentialSampler\n",
    "\n",
    "from datasets import UserModeImgDataset\n",
    "from models import DVBPR\n",
    "from trainers import ImgTrainer\n",
    "from utils.data import extract_embedding\n",
    "\n",
    "torch.multiprocessing.set_sharing_strategy('file_system')\n",
    "\n",
    "# Parameters\n",
    "RNG_SEED = 0\n",
    "TRAINING_PATH = os.path.join(\"data\", \"naive-user-train.csv\")\n",
    "EMBEDDING_PATH = os.path.join(\"data\", \"embedding-resnet50.npy\")\n",
    "VALIDATION_PATH = os.path.join(\"data\", \"naive-user-validation.csv\")\n",
    "IMAGES_PATH = os.path.join(\"data\", \"mini-images-224-224-v2\")\n",
    "CHECKPOINTS_DIR = os.path.join(\"checkpoints\")\n",
    "USE_GPU = True\n",
    "\n",
    "# Parameters (training)\n",
    "SETTINGS = {\n",
    "    \"dataloader:batch_size\": 256,#, 42_000,\n",
    "    \"dataloader:num_workers\": 1,#os.cpu_count(),\n",
    "    \"model:dim_latent\": 100,\n",
    "    \"model:dim_visual\": 100,\n",
    "    \"optimizer:lr\": 0.001,\n",
    "    \"optimizer:weight_decay\": 0.0001,\n",
    "    \"scheduler:factor\": 0.6,\n",
    "    \"scheduler:patience\": 2,\n",
    "    \"train:max_epochs\": 1, #150,\n",
    "    \"train:max_lrs\": 5,\n",
    "    \"train:non_blocking\": True,\n",
    "    \"train:train_per_valid_times\": 1,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Freezing RNG seed if needed\n",
    "if RNG_SEED is not None:\n",
    "    print(f\"\\nUsing random seed...\")\n",
    "    random.seed(RNG_SEED)\n",
    "    torch.manual_seed(RNG_SEED)\n",
    "    np.random.seed(RNG_SEED)\n",
    "\n",
    "# Load embedding from file\n",
    "print(f\"\\nLoading embedding from file... ({EMBEDDING_PATH})\")\n",
    "embedding = np.load(EMBEDDING_PATH, allow_pickle=True)\n",
    "\n",
    "# Extract features and \"id2index\" mapping\n",
    "print(\"\\nExtracting data into variables...\")\n",
    "embedding, id2index, index2fn = extract_embedding(embedding, verbose=True)\n",
    "print(f\">> Features shape: {embedding.shape}\")\n",
    "\n",
    "# DataLoaders initialization\n",
    "print(\"\\nInitialize DataLoaders\")\n",
    "# Training DataLoader\n",
    "train_dataset = UserModeImgDataset(\n",
    "    csv_file=TRAINING_PATH,\n",
    "    img_path=IMAGES_PATH,\n",
    "    id2index=id2index,\n",
    "    index2fn=index2fn\n",
    ")\n",
    "print(f\">> Training dataset: {len(train_dataset)}\")\n",
    "train_sampler = RandomSampler(train_dataset)\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=SETTINGS[\"dataloader:batch_size\"],\n",
    "    num_workers=SETTINGS[\"dataloader:num_workers\"],\n",
    "    pin_memory=True,\n",
    ")\n",
    "print(f\">> Training dataloader: {len(train_dataloader)}\")\n",
    "# Validation DataLoader\n",
    "valid_dataset = UserModeImgDataset(\n",
    "    csv_file=VALIDATION_PATH,\n",
    "    img_path=IMAGES_PATH,\n",
    "    id2index=id2index,\n",
    "    index2fn=index2fn\n",
    ")\n",
    "print(f\">> Validation dataset: {len(valid_dataset)}\")\n",
    "valid_sampler = SequentialSampler(valid_dataset)\n",
    "valid_dataloader = DataLoader(\n",
    "    valid_dataset,\n",
    "    batch_size=SETTINGS[\"dataloader:batch_size\"],\n",
    "    num_workers=SETTINGS[\"dataloader:num_workers\"],\n",
    "    pin_memory=True,\n",
    ")\n",
    "print(f\">> Validation dataloader: {len(valid_dataloader)}\")\n",
    "# Model initialization\n",
    "print(\"\\nInitialize model\")\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() and USE_GPU else \"cpu\")\n",
    "if torch.cuda.is_available() != USE_GPU:\n",
    "    print((f\"\\nNotice: Not using GPU - \"\n",
    "           f\"Cuda available ({torch.cuda.is_available()}) \"\n",
    "           f\"does not match USE_GPU ({USE_GPU})\"\n",
    "    ))\n",
    "N_USERS = len(set(train_dataset.ui))\n",
    "N_ITEMS = len(embedding)\n",
    "print(f\">> N_USERS = {N_USERS} | N_ITEMS = {N_ITEMS}\")\n",
    "print(torch.Tensor(embedding).shape)\n",
    "model = DVBPR(\n",
    "    N_USERS, N_ITEMS,  # Number of users and items\n",
    "    SETTINGS[\"model:dim_latent\"], SETTINGS[\"model:dim_visual\"],  # Size of internal spaces\n",
    ").to(device)\n",
    "\n",
    "# Training setup\n",
    "print(\"\\nSetting up training\")\n",
    "optimizer = optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=SETTINGS[\"optimizer:lr\"],\n",
    "    weight_decay=SETTINGS[\"optimizer:weight_decay\"],\n",
    ")\n",
    "criterion = nn.BCEWithLogitsLoss(reduction=\"sum\")\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode=\"max\", factor=SETTINGS[\"scheduler:factor\"],\n",
    "    patience=SETTINGS[\"scheduler:patience\"], verbose=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Training\n",
    "version = f\"DVBPR_wikimedia\"\n",
    "trainer = ImgTrainer(\n",
    "    model, device, criterion, optimizer, scheduler,\n",
    "    checkpoint_dir=CHECKPOINTS_DIR,\n",
    "    version=version,\n",
    ")\n",
    "best_model, best_acc, best_loss, best_epoch = trainer.run(\n",
    "    SETTINGS[\"train:max_epochs\"], SETTINGS[\"train:max_lrs\"],\n",
    "    {\"train\": train_dataloader, \"validation\": valid_dataloader},\n",
    "    train_valid_loops=SETTINGS[\"train:train_per_valid_times\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final result\n",
    "print(f\"\\nBest ACC {best_acc} reached at epoch {best_epoch}\")\n",
    "print(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
